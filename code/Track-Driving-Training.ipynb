{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import getcwd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#this function will crop and resize the images to save memory and make training faster\n",
    "#reduce the noise and use cv2.cvtColor(new_img, cv2.COLOR_BGR2YUV) as the Nvidia doc suggests,\n",
    "def preprocess_image(img):\n",
    "    #avoid input size error in keras model\n",
    "    new_img = img[50:140,:,:]\n",
    "    new_img = cv2.GaussianBlur(new_img, (3,3), 0)\n",
    "    new_img = cv2.resize(new_img,(200, 66), interpolation = cv2.INTER_AREA)\n",
    "    new_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2YUV)\n",
    "    return new_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# here we are creating extra training data\n",
    "def generate_training_data(image_paths, angles, batch_size=128):\n",
    "    image_paths, angles = shuffle(image_paths, angles)\n",
    "    X,y = ([],[])\n",
    "    while True:       \n",
    "        for i in range(len(angles)):\n",
    "            img = cv2.imread(image_paths[i])\n",
    "            angle = angles[i]\n",
    "            img = preprocess_image(img)\n",
    "            X.append(img)\n",
    "            y.append(angle)\n",
    "            if len(X) == batch_size:\n",
    "                yield (np.array(X), np.array(y))\n",
    "                X, y = ([],[])\n",
    "                image_paths, angles = shuffle(image_paths, angles)\n",
    "            # flip horizontally and invert steer angle, if magnitude is > 0.33 to avoid adding \n",
    "            # too much data without meaningful change\n",
    "            if abs(angle) > 0.33:\n",
    "                img = cv2.flip(img, 1)\n",
    "                angle *= -1\n",
    "                X.append(img)\n",
    "                y.append(angle)\n",
    "                if len(X) == batch_size:\n",
    "                    yield (np.array(X), np.array(y))\n",
    "                    X, y = ([],[])\n",
    "                    image_paths, angles = shuffle(image_paths, angles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data: (3831,) (3831,)\n",
      "Size of data: (3831,) (3831,)\n"
     ]
    }
   ],
   "source": [
    "#Here we are opening the driving_log file provided and reading the data\n",
    "lines=[]\n",
    "image_paths = []\n",
    "angles = []\n",
    "img_path_prepend = ['', getcwd() + './data/']\n",
    "pathnw =\"C:/Users/Abdullah's/CarND-Behavioral-Cloning-P3-master/driving_log.csv\"\n",
    "with open(pathnw) as csvfile:\n",
    "    driving_data = list(csv.reader(csvfile, skipinitialspace=True, delimiter=',', quoting=csv.QUOTE_NONE))\n",
    "    for row in driving_data[1:]:\n",
    "        # skip it if ~0 speed - not representative of driving behavior\n",
    "        if float(row[6]) < 0.1 :\n",
    "            continue\n",
    "        # get center image path and angle\n",
    "        image_paths.append(img_path_prepend[1] + row[0])\n",
    "        angles.append(float(row[3]))\n",
    "        # get left image path and angle\n",
    "        image_paths.append(img_path_prepend[1] + row[1])\n",
    "        #add a correction factor of .25 to the angle\n",
    "        angles.append(float(row[3])+0.25)\n",
    "        # get left image path and angle\n",
    "        image_paths.append(img_path_prepend[1] + row[2])\n",
    "        # add a correction factor of -.25 to the angle\n",
    "        angles.append(float(row[3])-0.25)\n",
    "\n",
    "image_paths = np.array(image_paths)\n",
    "angles = np.array(angles)\n",
    "print('Size of data:', image_paths.shape, angles.shape)\n",
    "print('Size of data:', image_paths.shape, angles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqTIUJEnV/wFrl+vMtzoacQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b912db9278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data after removing unwanted values: (927,) (927,)\n"
     ]
    }
   ],
   "source": [
    "# this is basically clean up tp the data that we have so that we dont overwhelm our machine while training (cause biases)\n",
    "num_bins = 23\n",
    "avg_samples_per_bin = len(angles)/num_bins\n",
    "hist, bins = np.histogram(angles, num_bins)\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "plt.plot((np.min(angles), np.max(angles)), (avg_samples_per_bin, avg_samples_per_bin), 'k-')\n",
    "#set keep probability for data from steering angles with more than half the average samples per angle\n",
    "keep_probs = []\n",
    "target = avg_samples_per_bin * .5\n",
    "for i in range(num_bins):\n",
    "    if hist[i] < target:\n",
    "        keep_probs.append(1.)\n",
    "    else:\n",
    "        keep_probs.append(1./(hist[i]/target))\n",
    "remove_list = []\n",
    "for i in range(len(angles)):\n",
    "    for j in range(num_bins):\n",
    "        if angles[i] > bins[j] and angles[i] <= bins[j+1]:\n",
    "            # delete from X and y with probability 1 - keep_probs[j]\n",
    "            if np.random.rand() > keep_probs[j]:\n",
    "                remove_list.append(i)\n",
    "image_paths = np.delete(image_paths, remove_list, axis=0)\n",
    "angles = np.delete(angles, remove_list)\n",
    "\n",
    "# print histogram to show the new distribution of steering angles\n",
    "hist, bins = np.histogram(angles, num_bins)\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "plt.plot((np.min(angles), np.max(angles)), (avg_samples_per_bin, avg_samples_per_bin), 'k-')\n",
    "plt.show()\n",
    "\n",
    "print('Size of data after removing unwanted values:', image_paths.shape, angles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "154s - loss: 0.0331 - val_loss: 0.0242\n",
      "Epoch 2/5\n",
      "44s - loss: 0.0205 - val_loss: 0.0187\n",
      "Epoch 3/5\n",
      "93s - loss: 0.0158 - val_loss: 0.0129\n",
      "Epoch 4/5\n",
      "95s - loss: 0.0106 - val_loss: 0.0073\n",
      "Epoch 5/5\n",
      "53s - loss: 0.0067 - val_loss: 0.0050\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# this is the Nvidia architecture modle \n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: (x / 127.5) - 1.0, input_shape=(66,200,3)))\n",
    "##Nvidia Model\n",
    "model.add(Convolution2D(24,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "model.add(Convolution2D(36,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "model.add(Convolution2D(48,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "model.add(Convolution2D(64,3,3,activation=\"relu\"))\n",
    "model.add(Convolution2D(64,3,3,activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "train_gen = generate_training_data(image_paths, angles, batch_size=64)\n",
    "val_gen = generate_training_data(image_paths, angles, batch_size=64)\n",
    "\n",
    "history = model.fit_generator(train_gen, validation_data=val_gen, nb_val_samples=2560, samples_per_epoch=23040, \n",
    "                                  nb_epoch=5, verbose=2, callbacks=[checkpoint])\n",
    "\n",
    "model.save('model.h5')\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
